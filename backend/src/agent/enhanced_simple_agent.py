"""å¢å¼ºç‰ˆ SimpleAgent - æ”¯æŒæµå¼å·¥å…·è°ƒç”¨"""

import json
import asyncio
from datetime import datetime
from typing import Optional, List, Dict, AsyncGenerator, TYPE_CHECKING, Union

from hello_agents.agents.simple_agent import SimpleAgent
from hello_agents.core.llm import HelloAgentsLLM
from hello_agents.core.config import Config
from hello_agents.core.message import Message
from hello_agents.core.streaming import StreamEvent, StreamEventType

# å¯¼å…¥ HelloClaw ä¸“ç”¨ LLMï¼ˆæ”¯æŒæµå¼å·¥å…·è°ƒç”¨ï¼‰
from .enhanced_llm import EnhancedHelloAgentsLLM, StreamToolEventType

if TYPE_CHECKING:
    from hello_agents.tools.registry import ToolRegistry


class EnhancedSimpleAgent(SimpleAgent):
    """å¢å¼ºç‰ˆ SimpleAgentï¼Œæ”¯æŒæµå¼å·¥å…·è°ƒç”¨

    ç»§æ‰¿ hello_agents çš„ SimpleAgentï¼Œå¢åŠ ï¼š
    - çœŸæ­£çš„æµå¼å·¥å…·è°ƒç”¨ï¼ˆä½¿ç”¨ EnhancedHelloAgentsLLMï¼‰
    - å·¥å…·è°ƒç”¨çŠ¶æ€çš„å®æ—¶æ¨é€

    Note:
        æ¨èä½¿ç”¨ EnhancedHelloAgentsLLM ä»¥è·å¾—å®Œæ•´çš„æµå¼å·¥å…·è°ƒç”¨æ”¯æŒã€‚
        å¦‚æœä½¿ç”¨æ™®é€š HelloAgentsLLMï¼Œæµå¼å·¥å…·è°ƒç”¨å°†å›é€€åˆ°åŸºç±»çš„éæµå¼æ¨¡å¼ã€‚
    """

    def __init__(
        self,
        name: str,
        llm: Union[HelloAgentsLLM, EnhancedHelloAgentsLLM],
        system_prompt: Optional[str] = None,
        config: Optional[Config] = None,
        tool_registry: Optional['ToolRegistry'] = None,
        enable_tool_calling: bool = True,
        max_tool_iterations: int = 10,
    ):
        """åˆå§‹åŒ– EnhancedSimpleAgent

        Args:
            name: Agent åç§°
            llm: LLM å®ä¾‹ï¼ˆæ¨èä½¿ç”¨ EnhancedHelloAgentsLLMï¼‰
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            config: é…ç½®å¯¹è±¡
            tool_registry: å·¥å…·æ³¨å†Œè¡¨ï¼ˆå¯é€‰ï¼‰
            enable_tool_calling: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨
            max_tool_iterations: æœ€å¤§å·¥å…·è°ƒç”¨è¿­ä»£æ¬¡æ•°
        """
        super().__init__(
            name=name,
            llm=llm,
            system_prompt=system_prompt,
            config=config,
            tool_registry=tool_registry,
            enable_tool_calling=enable_tool_calling,
            max_tool_iterations=max_tool_iterations,
        )

        # æ£€æŸ¥æ˜¯å¦æ”¯æŒæµå¼å·¥å…·è°ƒç”¨
        self._supports_streaming_tools = isinstance(llm, EnhancedHelloAgentsLLM)

    async def arun_stream_with_tools(
        self,
        input_text: str,
        **kwargs
    ) -> AsyncGenerator[StreamEvent, None]:
        """å¼‚æ­¥æµå¼è¿è¡Œï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰

        ä½¿ç”¨ EnhancedHelloAgentsLLM çš„ astream_invoke_with_tools æ–¹æ³•å®ç°ä¼˜é›…çš„æµå¼å·¥å…·è°ƒç”¨ã€‚

        Args:
            input_text: ç”¨æˆ·è¾“å…¥
            **kwargs: å…¶ä»–å‚æ•°

        Yields:
            StreamEvent: æµå¼äº‹ä»¶
        """
        session_start_time = datetime.now()

        # å‘é€å¼€å§‹äº‹ä»¶
        yield StreamEvent.create(
            StreamEventType.AGENT_START,
            self.name,
            input_text=input_text
        )

        print(f"\nğŸ¤– {self.name} å¼€å§‹å¤„ç†é—®é¢˜ï¼ˆæµå¼ï¼‰: {input_text}")

        try:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = self._build_messages(input_text)

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·
            if not self.enable_tool_calling or not self.tool_registry:
                # çº¯å¯¹è¯æ¨¡å¼ï¼Œä½¿ç”¨åŸºç±»çš„æ–¹æ³•
                async for event in self._stream_without_tools(messages, **kwargs):
                    yield event
                return

            # æ£€æŸ¥ LLM æ˜¯å¦æ”¯æŒæµå¼å·¥å…·è°ƒç”¨
            if not self._supports_streaming_tools:
                import warnings
                warnings.warn(
                    "å½“å‰ LLM ä¸æ”¯æŒæµå¼å·¥å…·è°ƒç”¨ï¼Œå°†ä½¿ç”¨éæµå¼æ¨¡å¼ã€‚"
                    "æ¨èä½¿ç”¨ EnhancedHelloAgentsLLM ä»¥è·å¾—æ›´å¥½çš„ä½“éªŒã€‚",
                    UserWarning
                )
                # å›é€€åˆ°åŸºç±»çš„éæµå¼æ¨¡å¼
                response = self.run(input_text, **kwargs)
                yield StreamEvent.create(
                    StreamEventType.AGENT_FINISH,
                    self.name,
                    result=response
                )
                return

            # === æµå¼å·¥å…·è°ƒç”¨æ¨¡å¼ ===
            tool_schemas = self._build_tool_schemas()
            print(f"ğŸ”§ å·²å¯ç”¨å·¥å…·è°ƒç”¨ï¼Œå¯ç”¨å·¥å…·: {list(self.tool_registry._tools.keys())}")

            current_iteration = 0
            final_response = ""
            # æ”¶é›†å·¥å…·è°ƒç”¨è®°å½•ï¼ˆç”¨äºå­˜å…¥ä¼šè¯ï¼‰
            tool_call_records: List[Dict[str, Any]] = []

            while current_iteration < self.max_tool_iterations:
                current_iteration += 1

                # å‘é€æ­¥éª¤å¼€å§‹äº‹ä»¶
                yield StreamEvent.create(
                    StreamEventType.STEP_START,
                    self.name,
                    step=current_iteration,
                    max_steps=self.max_tool_iterations
                )

                print(f"\n--- ç¬¬ {current_iteration} è½® ---")
                print("ğŸ’­ LLM è¾“å‡º: ", end="", flush=True)

                # ä½¿ç”¨ LLM çš„æµå¼å·¥å…·è°ƒç”¨æ–¹æ³•
                try:
                    async for event in self.llm.astream_invoke_with_tools(
                        messages=messages,
                        tools=tool_schemas,
                        tool_choice="auto",
                        **kwargs
                    ):
                        # å¤„ç†æ–‡æœ¬å†…å®¹
                        if event.event_type == StreamToolEventType.CONTENT:
                            yield StreamEvent.create(
                                StreamEventType.LLM_CHUNK,
                                self.name,
                                chunk=event.content,
                                step=current_iteration
                            )
                            print(event.content, end="", flush=True)

                        # å·¥å…·è°ƒç”¨å¼€å§‹ï¼ˆæ‰“å°ä¿¡æ¯ï¼Œä¸å‘é€äº‹ä»¶ï¼‰
                        elif event.event_type == StreamToolEventType.TOOL_CALL_START:
                            pass  # ç­‰å·¥å…·è°ƒç”¨å®Œæˆåå†å‘é€äº‹ä»¶

                    print()  # æ¢è¡Œ

                except Exception as e:
                    error_msg = f"LLM è°ƒç”¨å¤±è´¥: {str(e)}"
                    print(f"\nâŒ {error_msg}")
                    yield StreamEvent.create(
                        StreamEventType.ERROR,
                        self.name,
                        error=error_msg
                    )
                    break

                # è·å–ç´¯ç§¯ç»“æœ
                result = self.llm.get_last_stream_tool_result()
                if result is None:
                    break

                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                complete_tool_calls = result.get_complete_tool_calls()

                # æ— è®ºæ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼Œéƒ½ä¿å­˜æœ¬è½®çš„æ–‡æœ¬å†…å®¹
                if result.content:
                    final_response = result.content

                if not complete_tool_calls:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›
                    if not final_response:
                        final_response = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
                    # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
                    preview = final_response[:100] + "..." if len(final_response) > 100 else final_response
                    print(f"ğŸ’¬ ç›´æ¥å›å¤: {preview}")
                    break

                print(f"ğŸ”§ å‡†å¤‡æ‰§è¡Œ {len(complete_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨...")

                # å°†åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°å†å²
                messages.append(result.to_assistant_message())

                # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                for tc in complete_tool_calls:
                    tool_name = tc["name"]
                    tool_call_id = tc["id"]

                    try:
                        arguments = json.loads(tc["arguments"])
                    except json.JSONDecodeError as e:
                        print(f"âŒ å·¥å…·å‚æ•°è§£æå¤±è´¥: {e}")
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call_id,
                            "content": f"é”™è¯¯ï¼šå‚æ•°æ ¼å¼ä¸æ­£ç¡® - {str(e)}"
                        })
                        continue

                    print(f"ğŸ¬ è°ƒç”¨å·¥å…·: {tool_name}({arguments})")

                    # å‘é€å·¥å…·è°ƒç”¨å¼€å§‹äº‹ä»¶
                    yield StreamEvent.create(
                        StreamEventType.TOOL_CALL_START,
                        self.name,
                        tool_name=tool_name,
                        tool_call_id=tool_call_id,
                        args=arguments
                    )

                    # è®©å‡ºæ§åˆ¶æƒï¼Œç¡®ä¿ SSE å‘é€ tool_start äº‹ä»¶
                    await asyncio.sleep(0)

                    # æ‰§è¡Œå·¥å…·
                    exec_result = self._execute_tool_call(tool_name, arguments)

                    # æˆªæ–­æ˜¾ç¤º
                    result_preview = exec_result[:200] + "..." if len(exec_result) > 200 else exec_result
                    if exec_result.startswith("âŒ"):
                        print(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {result_preview}")
                    else:
                        print(f"ğŸ‘€ è§‚å¯Ÿ: {result_preview}")

                    # å‘é€å·¥å…·è°ƒç”¨å®Œæˆäº‹ä»¶
                    yield StreamEvent.create(
                        StreamEventType.TOOL_CALL_FINISH,
                        self.name,
                        tool_name=tool_name,
                        tool_call_id=tool_call_id,
                        result=exec_result
                    )

                    # è®°å½•å·¥å…·è°ƒç”¨ï¼ˆç”¨äºå­˜å…¥ä¼šè¯ï¼‰
                    tool_call_records.append({
                        "name": tool_name,
                        "args": arguments,
                        "result": exec_result,
                        "status": "error" if exec_result.startswith("âŒ") else "done"
                    })

                    # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call_id,
                        "content": exec_result
                    })

                # å‘é€æ­¥éª¤å®Œæˆäº‹ä»¶
                yield StreamEvent.create(
                    StreamEventType.STEP_FINISH,
                    self.name,
                    step=current_iteration
                )

            # å¦‚æœè¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè·å–æœ€åä¸€æ¬¡å›ç­”
            if current_iteration >= self.max_tool_iterations and not final_response:
                print("â° å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè·å–æœ€ç»ˆå›ç­”...")

                try:
                    async for chunk in self.llm.astream_invoke(messages, **kwargs):
                        final_response += chunk
                        yield StreamEvent.create(
                            StreamEventType.LLM_CHUNK,
                            self.name,
                            chunk=chunk
                        )
                        print(chunk, end="", flush=True)
                    print()
                except Exception as e:
                    print(f"âŒ æœ€ç»ˆå›ç­”å¤±è´¥: {e}")
                    result = self.llm.get_last_stream_tool_result()
                    final_response = result.content if result else "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"

            # ä¿å­˜åˆ°å†å²è®°å½•ï¼ˆæŒ‰ç…§ OpenAI è§„èŒƒæ ¼å¼ï¼‰
            self.add_message(Message(input_text, "user"))

            # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œä¿å­˜å·¥å…·è°ƒç”¨æ¶ˆæ¯
            if tool_call_records:
                # ä¿å­˜ assistant æ¶ˆæ¯ï¼ˆåŒ…å« tool_callsï¼‰
                tool_calls_for_message = [
                    {
                        "id": f"call_{i}",
                        "type": "function",
                        "function": {
                            "name": tc["name"],
                            "arguments": json.dumps(tc["args"])
                        }
                    }
                    for i, tc in enumerate(tool_call_records)
                ]
                self.add_message(Message(
                    "",  # å·¥å…·è°ƒç”¨æ—¶å¯èƒ½æ²¡æœ‰æ–‡æœ¬å†…å®¹
                    "assistant",
                    metadata={"tool_calls": tool_calls_for_message}
                ))

                # ä¿å­˜æ¯ä¸ª tool æ¶ˆæ¯
                for i, tc in enumerate(tool_call_records):
                    self.add_message(Message(
                        tc["result"],
                        "tool",
                        metadata={"tool_call_id": f"call_{i}"}
                    ))

            # ä¿å­˜æœ€ç»ˆ assistant å›ç­”
            if final_response:
                self.add_message(Message(final_response, "assistant"))

            duration = (datetime.now() - session_start_time).total_seconds()
            print(f"\nâœ… å®Œæˆï¼Œè€—æ—¶ {duration:.2f}sï¼Œå…± {current_iteration} è½®")

            # å‘é€å®Œæˆäº‹ä»¶
            yield StreamEvent.create(
                StreamEventType.AGENT_FINISH,
                self.name,
                result=final_response
            )

        except Exception as e:
            print(f"âŒ Agent æ‰§è¡Œå¤±è´¥: {e}")
            yield StreamEvent.create(
                StreamEventType.ERROR,
                self.name,
                error=str(e),
                error_type=type(e).__name__
            )
            # ä¸è¦ raiseï¼Œç¡®ä¿æµå¼å“åº”æ­£å¸¸ç»“æŸ
            # å‘é€å®Œæˆäº‹ä»¶ä»¥ä¼˜é›…ç»“æŸ
            yield StreamEvent.create(
                StreamEventType.AGENT_FINISH,
                self.name,
                result=""  # ç©ºç»“æœè¡¨ç¤ºå¤±è´¥
            )

    async def _stream_without_tools(
        self,
        messages: List[Dict],
        **kwargs
    ) -> AsyncGenerator[StreamEvent, None]:
        """çº¯å¯¹è¯æ¨¡å¼ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰"""
        print("ğŸ“ çº¯å¯¹è¯æ¨¡å¼ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰")

        full_response = ""
        async for chunk in self.llm.astream_invoke(messages, **kwargs):
            full_response += chunk
            yield StreamEvent.create(
                StreamEventType.LLM_CHUNK,
                self.name,
                chunk=chunk
            )
            print(chunk, end="", flush=True)

        print()

        # ä¿å­˜å†å²
        self.add_message(Message(messages[-1]["content"], "user"))
        self.add_message(Message(full_response, "assistant"))

        print(f"ğŸ’¬ å›å¤å®Œæˆ")

        yield StreamEvent.create(
            StreamEventType.AGENT_FINISH,
            self.name,
            result=full_response
        )
